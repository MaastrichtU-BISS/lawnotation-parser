{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script that merges annotations made in Lawnotation.org. The input data need to have the same labelset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotations_gpt-5.1_2025-11-20_15-13-39_fixed.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify input and output folders\n",
    "input_folder = r'./input'\n",
    "output_file = r'./output/merged_annotations.json'\n",
    "\n",
    "os.listdir(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotator_mapping = {\n",
    "#     \"file1.json\": {1: 2, 2: 1},  # Swap annotators 1 and 2 in file1.json\n",
    "#     \"file2.json\": {3: 1, 2: 3}   # Remap annotators in file2.json\n",
    "# }\n",
    "annotator_mapping = {}\n",
    "\n",
    "# output_file = r\"C:\\Users\\gijs.vandijck\\Downloads\\test_GDPR\\merged_annotations.json\"\n",
    "\n",
    "# merge_json_files(input_folder, output_file, annotator_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Provide a mapping in the form of a JSON string, such as {\"1\": 2, \"2\": 3}, or leave it blank if no mapping is needed.\n",
    "# ## If a document in File 1 has an assignment from annotator: 1, the script will change it to annotator: 2 based on the mapping { \"1\": 2, \"2\": 3 }. Similarly, annotator: 2 will be changed to annotator: 3 in both files.\n",
    "# annotator_mapping = {} #if desired, enter annotator mapping as JSON (e.g., {\\\"1\\\": 2, \\\"3\\\": 2}): \")\n",
    "\n",
    "# # Main block where the user provides input and output paths\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Load all JSON files from the input folder\n",
    "#     json_files = load_json_files(input_folder)\n",
    "\n",
    "#     # Merge the files using the provided annotator mapping\n",
    "#     merged_data = merge_json_files(json_files, annotator_mapping)\n",
    "\n",
    "#     # Save the merged data to the specified output file\n",
    "#     with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "#         json.dump(merged_data, out_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "#     print(f\"Merged JSON saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to load all JSON files from a folder\n",
    "def load_json_files(folder_path):\n",
    "    return glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "\n",
    "# Function to merge multiple JSON files\n",
    "def merge_json_files(json_files, annotator_mapping, merged_name=\"merged annotations\", merged_desc=\"Merged annotations\"):\n",
    "    merged_data = None\n",
    "    \n",
    "    # Loop through each file to merge\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Apply annotator mapping (if any)\n",
    "        for doc in data['documents']:\n",
    "            for assignment in doc['assignments']:\n",
    "                if assignment['annotator'] in annotator_mapping:\n",
    "                    assignment['annotator'] = annotator_mapping[assignment['annotator']]\n",
    "\n",
    "        # Initialize merged_data with the first file\n",
    "        if merged_data is None:\n",
    "            merged_data = data\n",
    "        else:\n",
    "            merged_data = merge_annotations(merged_data, data)\n",
    "\n",
    "    # Update merged metadata (name and desc)\n",
    "    merged_data['name'] = merged_name\n",
    "    merged_data['desc'] = merged_desc\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "# Function to merge document annotations\n",
    "def merge_annotations(data1, data2):\n",
    "    merged_documents = {doc['name']: doc for doc in data1['documents']}\n",
    "\n",
    "    for doc in data2['documents']:\n",
    "        if doc['name'] in merged_documents:\n",
    "            # Merge annotations of the same document\n",
    "            merged_doc = merged_documents[doc['name']]\n",
    "            merged_doc['assignments'].extend(doc['assignments'])\n",
    "        else:\n",
    "            # Add new document\n",
    "            merged_documents[doc['name']] = doc\n",
    "\n",
    "    data1['documents'] = list(merged_documents.values())\n",
    "\n",
    "    # Update counts section based on merged documents\n",
    "    data1['counts']['documents'] = len(data1['documents'])\n",
    "    data1['counts']['assignments'] = sum(len(doc['assignments']) for doc in data1['documents'])\n",
    "    data1['counts']['annotators'] = len(set(a['annotator'] for doc in data1['documents'] for a in doc['assignments']))\n",
    "    data1['counts']['annotations'] = sum(len(a['annotations']) for doc in data1['documents'] for a in doc['assignments'])\n",
    "    data1['counts']['relations'] = sum(len(a.get('relations', [])) for doc in data1['documents'] for a in doc['assignments'])\n",
    "\n",
    "    return data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged JSON saved as ./output/merged_annotations.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load all JSON files from the input folder\n",
    "    json_files = load_json_files(input_folder)\n",
    "\n",
    "    # Merge the files using the provided annotator mapping\n",
    "    merged_data = merge_json_files(json_files, annotator_mapping)\n",
    "\n",
    "    # Save the merged data to the specified output file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        json.dump(merged_data, out_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Merged JSON saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated confidence scores and saved to ./output/merged_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# With LLM annotations, non-integer confidence scores may be assigned (e.g., 0.8). This causes issues when importing the data in Lawnotation.\n",
    "\n",
    "# Load the merged JSON file\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    merged_data = json.load(f)\n",
    "\n",
    "# Update confidence scores that are not 0, 1, 2, 3, 4, or 5\n",
    "valid_confidence_scores = {0, 1, 2, 3, 4, 5}\n",
    "\n",
    "for doc in merged_data[\"documents\"]:\n",
    "    for assignment in doc[\"assignments\"]:\n",
    "        for annotation in assignment[\"annotations\"]:\n",
    "            if annotation[\"confidence_rating\"] not in valid_confidence_scores:\n",
    "                annotation[\"confidence_rating\"] = 0  # Set invalid scores to 0\n",
    "\n",
    "# Save the updated JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Updated confidence scores and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./output/merged_annotations.json has been cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "from adapters import Gpt2LawnotationAll\n",
    "\n",
    "# Function to clean unnecessary spaces in labels\n",
    "def clean_labels(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Remove spaces in 'name' under 'labels'\n",
    "    for label in data['labelset']['labels']:\n",
    "        label['name'] = label['name'].strip()\n",
    "\n",
    "    # Remove spaces in 'label' under 'annotations'\n",
    "    # Extend annotations with correct indices using adapters\n",
    "    order = 1\n",
    "    for doc in data['documents']:\n",
    "        for assignment in doc['assignments']:\n",
    "            adapter = Gpt2LawnotationAll(doc['full_text'])\n",
    "            converted_annotations, repetitions = adapter.convert(assignment['annotations'])\n",
    "            assignment['annotations'] = converted_annotations\n",
    "            assignment['repetitions'] = repetitions\n",
    "            assignment['order'] = order\n",
    "            order += 1\n",
    "            for annotation in assignment['annotations']:\n",
    "                annotation['label'] = annotation['label'].strip()\n",
    "\n",
    "    # Save the cleaned data back to the same file\n",
    "    with open(file_path, 'w', encoding='utf-8') as out_file:\n",
    "        json.dump(data, out_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"File {file_path} has been cleaned and saved.\")\n",
    "\n",
    "clean_labels(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
